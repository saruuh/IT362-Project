{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c3c584",
   "metadata": {},
   "source": [
    "# IT362: Principles of Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ac449a",
   "metadata": {},
   "source": [
    "## Phase 1: Data Collection Research and Assessment  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca1870d",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "The **Natural Disaster Prediction Model: PREDINA** aims to analyze and predict the impacts of natural disasters based on historical data, with a focus on enhancing disaster preparedness and response strategies. The main research question guiding this project is: *How can historical data on natural disasters inform future predictions and improve community resilience?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee887f",
   "metadata": {},
   "source": [
    "### 2. Importing Libraries\n",
    "In this section, we will import the necessary libraries for our analysis and data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42176333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install openpyxl\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f01a4",
   "metadata": {},
   "source": [
    "### 3. Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28710ab0",
   "metadata": {},
   "source": [
    "- #### **EM-DAT: The International Disaster Database**\n",
    "The EM-DAT Public Table is a global disaster database maintained by CRED, tracking natural and technological disasters. It includes data on fatalities, affected populations, and economic damages, and is used for research and disaster management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6134a5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          DisNo. Historic Classification Key Disaster Group Disaster Subgroup  \\\n",
      "0  1999-9388-DJI       No    nat-cli-dro-dro        Natural    Climatological   \n",
      "1  1999-9388-SDN       No    nat-cli-dro-dro        Natural    Climatological   \n",
      "2  1999-9388-SOM       No    nat-cli-dro-dro        Natural    Climatological   \n",
      "3  2000-0001-AGO       No    tec-tra-roa-roa  Technological         Transport   \n",
      "4  2000-0002-AGO       No    nat-hyd-flo-riv        Natural      Hydrological   \n",
      "\n",
      "  Disaster Type Disaster Subtype External IDs Event Name  ISO  ...  \\\n",
      "0       Drought          Drought          NaN        NaN  DJI  ...   \n",
      "1       Drought          Drought          NaN        NaN  SDN  ...   \n",
      "2       Drought          Drought          NaN        NaN  SOM  ...   \n",
      "3          Road             Road          NaN        NaN  AGO  ...   \n",
      "4         Flood   Riverine flood          NaN        NaN  AGO  ...   \n",
      "\n",
      "  Reconstruction Costs ('000 US$) Reconstruction Costs, Adjusted ('000 US$)  \\\n",
      "0                             NaN                                       NaN   \n",
      "1                             NaN                                       NaN   \n",
      "2                             NaN                                       NaN   \n",
      "3                             NaN                                       NaN   \n",
      "4                             NaN                                       NaN   \n",
      "\n",
      "  Insured Damage ('000 US$) Insured Damage, Adjusted ('000 US$)  \\\n",
      "0                       NaN                                 NaN   \n",
      "1                       NaN                                 NaN   \n",
      "2                       NaN                                 NaN   \n",
      "3                       NaN                                 NaN   \n",
      "4                       NaN                                 NaN   \n",
      "\n",
      "  Total Damage ('000 US$) Total Damage, Adjusted ('000 US$)        CPI  \\\n",
      "0                     NaN                               NaN  58.111474   \n",
      "1                     NaN                               NaN  56.514291   \n",
      "2                     NaN                               NaN  56.514291   \n",
      "3                     NaN                               NaN  56.514291   \n",
      "4                 10000.0                           17695.0  56.514291   \n",
      "\n",
      "                                         Admin Units  Entry Date  Last Update  \n",
      "0  [{\"adm1_code\":1093,\"adm1_name\":\"Ali Sabieh\"},{...  2006-03-01   2023-09-25  \n",
      "1  [{\"adm1_code\":2757,\"adm1_name\":\"Northern Darfu...  2006-03-08   2023-09-25  \n",
      "2  [{\"adm1_code\":2691,\"adm1_name\":\"Bay\"},{\"adm1_c...  2006-03-08   2023-09-25  \n",
      "3                                                NaN  2004-10-27   2023-09-25  \n",
      "4  [{\"adm2_code\":4214,\"adm2_name\":\"Baia Farta\"},{...  2005-02-03   2023-09-25  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "emdat_df = pd.read_excel(\"Datasets/emdat.xlsx\")\n",
    "print(emdat_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74994bc",
   "metadata": {},
   "source": [
    "- #### **Kaggle Dataset : ALL NATURAL DISASTERS 1900-2021 / EOSDIS**\n",
    "This dataset, hosted on Kaggle, provides a record of natural disasters worldwide from 1900 to 2021, sourced from NASA's Earth Observing System Data and Information System (EOSDIS). It includes details such as disaster type, location, dates, and impacts (e.g., fatalities, affected populations, and economic damages), making it useful for analyzing historical disaster trends and impacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0309ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year   Seq Glide Disaster Group Disaster Subgroup      Disaster Type  \\\n",
      "0  1900  9002   NaN        Natural    Climatological            Drought   \n",
      "1  1900  9001   NaN        Natural    Climatological            Drought   \n",
      "2  1902    12   NaN        Natural       Geophysical         Earthquake   \n",
      "3  1902     3   NaN        Natural       Geophysical  Volcanic activity   \n",
      "4  1902    10   NaN        Natural       Geophysical  Volcanic activity   \n",
      "\n",
      "  Disaster Subtype Disaster Subsubtype   Event Name     Country  ...  \\\n",
      "0          Drought                 NaN          NaN  Cabo Verde  ...   \n",
      "1          Drought                 NaN          NaN       India  ...   \n",
      "2  Ground movement                 NaN          NaN   Guatemala  ...   \n",
      "3         Ash fall                 NaN  Santa Maria   Guatemala  ...   \n",
      "4         Ash fall                 NaN  Santa Maria   Guatemala  ...   \n",
      "\n",
      "  No Affected No Homeless Total Affected Insured Damages ('000 US$)  \\\n",
      "0         NaN         NaN            NaN                        NaN   \n",
      "1         NaN         NaN            NaN                        NaN   \n",
      "2         NaN         NaN            NaN                        NaN   \n",
      "3         NaN         NaN            NaN                        NaN   \n",
      "4         NaN         NaN            NaN                        NaN   \n",
      "\n",
      "  Total Damages ('000 US$)       CPI Adm Level Admin1 Code Admin2 Code  \\\n",
      "0                      NaN  3.221647       NaN         NaN         NaN   \n",
      "1                      NaN  3.221647       NaN         NaN         NaN   \n",
      "2                  25000.0  3.350513       NaN         NaN         NaN   \n",
      "3                      NaN  3.350513       NaN         NaN         NaN   \n",
      "4                      NaN  3.350513       NaN         NaN         NaN   \n",
      "\n",
      "  Geo Locations  \n",
      "0           NaN  \n",
      "1           NaN  \n",
      "2           NaN  \n",
      "3           NaN  \n",
      "4           NaN  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "kaggle_df = pd.read_csv(\"Datasets/EOSDIS.csv\")\n",
    "print(kaggle_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb9d1d",
   "metadata": {},
   "source": [
    "- ### **Global Disaster Alert and Coordination System (GDACS)**\n",
    "The GDACS API provides real-time alerts on natural disasters such as earthquakes, tsunamis, and storms, offering data on disaster type, location, magnitude, and impact. It is useful for monitoring, coordinating disaster response efforts, and supplementing data for building predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f8c757",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'end_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 62\u001b[0m\n\u001b[1;32m     58\u001b[0m start_date \u001b[38;5;241m=\u001b[39m properties\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfromdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1900-01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     61\u001b[0m start_year, start_month, start_day \u001b[38;5;241m=\u001b[39m start_date\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m end_year, end_month, end_day \u001b[38;5;241m=\u001b[39m \u001b[43mend_date\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Determine magnitude based on alert level\u001b[39;00m\n\u001b[1;32m     65\u001b[0m alert_level \u001b[38;5;241m=\u001b[39m properties\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malertlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGreen\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'end_date' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# API URL\n",
    "api_url = \"https://www.gdacs.org/gdacsapi/api/events/geteventlist/EVENTS4APP\"\n",
    "\n",
    "# API Parameters (Modify dates as needed)\n",
    "params = {\n",
    "    \"from\": \"2010-01-01\",  # Modify this\n",
    "    \"to\": \"2024-02-06\",  # Modify this\n",
    "    \"source\": \"DFO\",\n",
    "    \"alertlevel\": \"RED\",\n",
    "    \"datatype\": \"4DAYS\",\n",
    "    \"type\": \"json\"\n",
    "}\n",
    "\n",
    "# Send API request\n",
    "response = requests.get(api_url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Convert response to JSON\n",
    "    features = data.get(\"features\", [])  # Extract list of disaster events\n",
    "\n",
    "    # CSV Output File\n",
    "    csv_filename = \"gdacs_disasters.csv\"\n",
    "\n",
    "    # Define CSV Headers\n",
    "    headers = [\n",
    "        \"Event Name\", \"Country\", \"ISO\", \"Disaster Group\", \"Disaster Subgroup\",\n",
    "        \"Disaster Type\", \"Disaster Subtype\", \"Latitude\", \"Longitude\",\n",
    "        \"Start Year\", \"Start Month\", \"Start Day\", \"End Year\", \"End Month\", \"End Day\",\n",
    "        \"Magnitude\", \"Affected People\"\n",
    "    ]\n",
    "\n",
    "    # Write to CSV\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)  # Write header row\n",
    "\n",
    "        for feature in features:\n",
    "            properties = feature.get(\"properties\", {})\n",
    "            geometry = feature.get(\"geometry\", {})\n",
    "\n",
    "            # Extracting required fields\n",
    "            event_name = properties.get(\"name\", \"Unknown\")\n",
    "            country = properties.get(\"country\", \"Unknown\")\n",
    "            iso = properties.get(\"iso3\", \"Unknown\")\n",
    "            disaster_group = properties.get(\"Class\", \"Unknown\")  # Adjust as needed\n",
    "            disaster_subgroup = \"Unknown\"  # No direct field found in API\n",
    "            disaster_type = properties.get(\"eventtype\", \"Unknown\")\n",
    "            disaster_subtype = \"Unknown\"  # No direct field found in API\n",
    "\n",
    "            # Extract latitude & longitude\n",
    "            latitude, longitude = None, None\n",
    "            if geometry.get(\"type\") == \"Point\":\n",
    "                coordinates = geometry.get(\"coordinates\", [])\n",
    "                if len(coordinates) >= 2:\n",
    "                    longitude, latitude = coordinates[0], coordinates[1]\n",
    "\n",
    "            # Extract start and end dates\n",
    "            start_date = properties.get(\"fromdate\", \"1900-01-01\").split(\"T\")[0]\n",
    "            \n",
    "\n",
    "            start_year, start_month, start_day = start_date.split(\"-\")\n",
    "            end_year, end_month, end_day = end_date.split(\"-\")\n",
    "\n",
    "            # Determine magnitude based on alert level\n",
    "            alert_level = properties.get(\"alertlevel\", \"Green\")\n",
    "            if alert_level == \"RED\":\n",
    "                magnitude = \">4\"\n",
    "            elif alert_level == \"ORANGE\":\n",
    "                magnitude = \">2\"\n",
    "            else:\n",
    "                magnitude = \"<=2\"\n",
    "\n",
    "            # Affected people\n",
    "            affected_people = properties.get(\"totalaffected\", \"N/A\")\n",
    "\n",
    "            # Write row to CSV\n",
    "            writer.writerow([\n",
    "                event_name, country, iso, disaster_group, disaster_subgroup,\n",
    "                disaster_type, disaster_subtype, latitude, longitude,\n",
    "                start_year, start_month, start_day, end_year, end_month, end_day,\n",
    "                magnitude, affected_people\n",
    "            ])\n",
    "\n",
    "    print(f\"Data successfully saved to {csv_filename}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status Code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15cf90",
   "metadata": {},
   "source": [
    "Convert Data Types to Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "976255a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\"Latitude\", \"Longitude\", \"Start Year\", \"Start Month\", \"Start Day\", \n",
    "                   \"End Year\", \"End Month\", \"End Day\", \"Total Deaths\", \"No. Injured\", \n",
    "                   \"No. Affected\", \"No. Homeless\", \"Total Affected\", \"Total Damages ('000 US$)\", \"CPI\", \"Magnitude\"]\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in emdat_df.columns:\n",
    "        emdat_df[col] = pd.to_numeric(emdat_df[col], errors='coerce')  # Convert to numeric, set errors to NaN\n",
    "    if col in kaggle_df.columns:\n",
    "        kaggle_df[col] = pd.to_numeric(kaggle_df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6d8b3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated df1 column types:\n",
      " DisNo.                                        object\n",
      "Historic                                      object\n",
      "Classification Key                            object\n",
      "Disaster Group                                object\n",
      "Disaster Subgroup                             object\n",
      "Disaster Type                                 object\n",
      "Disaster Subtype                              object\n",
      "External IDs                                  object\n",
      "Event Name                                    object\n",
      "ISO                                           object\n",
      "Country                                       object\n",
      "Subregion                                     object\n",
      "Region                                        object\n",
      "Location                                      object\n",
      "Origin                                        object\n",
      "Associated Types                              object\n",
      "OFDA/BHA Response                             object\n",
      "Appeal                                        object\n",
      "Declaration                                   object\n",
      "AID Contribution ('000 US$)                  float64\n",
      "Magnitude                                    float64\n",
      "Magnitude Scale                               object\n",
      "Latitude                                     float64\n",
      "Longitude                                    float64\n",
      "River Basin                                   object\n",
      "Start Year                                     int64\n",
      "Start Month                                  float64\n",
      "Start Day                                    float64\n",
      "End Year                                       int64\n",
      "End Month                                    float64\n",
      "End Day                                      float64\n",
      "Total Deaths                                 float64\n",
      "No. Injured                                  float64\n",
      "No. Affected                                 float64\n",
      "No. Homeless                                 float64\n",
      "Total Affected                               float64\n",
      "Reconstruction Costs ('000 US$)              float64\n",
      "Reconstruction Costs, Adjusted ('000 US$)    float64\n",
      "Insured Damage ('000 US$)                    float64\n",
      "Insured Damage, Adjusted ('000 US$)          float64\n",
      "Total Damage ('000 US$)                      float64\n",
      "Total Damage, Adjusted ('000 US$)            float64\n",
      "CPI                                          float64\n",
      "Admin Units                                   object\n",
      "Entry Date                                    object\n",
      "Last Update                                   object\n",
      "dtype: object\n",
      "Updated df2 column types:\n",
      " Year                           object\n",
      "Seq                             int64\n",
      "Glide                          object\n",
      "Disaster Group                 object\n",
      "Disaster Subgroup              object\n",
      "Disaster Type                  object\n",
      "Disaster Subtype               object\n",
      "Disaster Subsubtype            object\n",
      "Event Name                     object\n",
      "Country                        object\n",
      "ISO                            object\n",
      "Region                         object\n",
      "Continent                      object\n",
      "Location                       object\n",
      "Origin                         object\n",
      "Associated Dis                 object\n",
      "Associated Dis2                object\n",
      "OFDA Response                  object\n",
      "Appeal                         object\n",
      "Declaration                    object\n",
      "Aid Contribution              float64\n",
      "Dis Mag Value                 float64\n",
      "Dis Mag Scale                  object\n",
      "Latitude                      float64\n",
      "Longitude                     float64\n",
      "Local Time                     object\n",
      "River Basin                    object\n",
      "Start Year                      int64\n",
      "Start Month                   float64\n",
      "Start Day                     float64\n",
      "End Year                        int64\n",
      "End Month                     float64\n",
      "End Day                       float64\n",
      "Total Deaths                  float64\n",
      "No Injured                    float64\n",
      "No Affected                   float64\n",
      "No Homeless                   float64\n",
      "Total Affected                float64\n",
      "Insured Damages ('000 US$)    float64\n",
      "Total Damages ('000 US$)      float64\n",
      "CPI                           float64\n",
      "Adm Level                      object\n",
      "Admin1 Code                    object\n",
      "Admin2 Code                    object\n",
      "Geo Locations                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "string_columns = [\"Year\", \"Disaster Group\", \"Disaster Subgroup\", \"Disaster Type\", \"ISO\", \"Magnitude Scale\"]\n",
    "\n",
    "for col in string_columns:\n",
    "    if col in emdat_df.columns:\n",
    "        emdat_df[col] = emdat_df[col].astype(str).str.strip()  # Ensure string format\n",
    "    if col in kaggle_df.columns:\n",
    "        kaggle_df[col] = kaggle_df[col].astype(str).str.strip()\n",
    "\n",
    "print(\"Updated df1 column types:\\n\", emdat_df.dtypes)\n",
    "print(\"Updated df2 column types:\\n\",kaggle_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de665b7d",
   "metadata": {},
   "source": [
    "### 4. Data Intergration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95f6bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emdat_df['Year'] = emdat_df['Year'].astype(str).str[:4]\n",
    "\n",
    "emdat_df.rename(columns={'DisNo.': 'Year'}, inplace=True)\n",
    "emdat_df.rename(columns={\"Total Damage, Adjusted ('000 US$)\": \"Total Damages ('000 US$')\"}, inplace=True)\n",
    "\n",
    "kaggle_df.rename(columns={'Dis Mag Value': 'Magnitude'}, inplace=True)\n",
    "kaggle_df.rename(columns={'Dis Mag Scale': 'Magnitude Scale'}, inplace=True)\n",
    "kaggle_df.rename(columns={'No Injured': 'No. Injured'}, inplace=True)\n",
    "kaggle_df.rename(columns={'No Affected': 'No Affected'}, inplace=True)\n",
    "kaggle_df.rename(columns={'No Homeless': 'No. Homeless'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "859bf58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 columns and types:\n",
      " Year                                          object\n",
      "Historic                                      object\n",
      "Classification Key                            object\n",
      "Disaster Group                                object\n",
      "Disaster Subgroup                             object\n",
      "Disaster Type                                 object\n",
      "Disaster Subtype                              object\n",
      "External IDs                                  object\n",
      "Event Name                                    object\n",
      "ISO                                           object\n",
      "Country                                       object\n",
      "Subregion                                     object\n",
      "Region                                        object\n",
      "Location                                      object\n",
      "Origin                                        object\n",
      "Associated Types                              object\n",
      "OFDA/BHA Response                             object\n",
      "Appeal                                        object\n",
      "Declaration                                   object\n",
      "AID Contribution ('000 US$)                  float64\n",
      "Magnitude                                    float64\n",
      "Magnitude Scale                               object\n",
      "Latitude                                     float64\n",
      "Longitude                                    float64\n",
      "River Basin                                   object\n",
      "Start Year                                     int64\n",
      "Start Month                                  float64\n",
      "Start Day                                    float64\n",
      "End Year                                       int64\n",
      "End Month                                    float64\n",
      "End Day                                      float64\n",
      "Total Deaths                                 float64\n",
      "No. Injured                                  float64\n",
      "No. Affected                                 float64\n",
      "No. Homeless                                 float64\n",
      "Total Affected                               float64\n",
      "Reconstruction Costs ('000 US$)              float64\n",
      "Reconstruction Costs, Adjusted ('000 US$)    float64\n",
      "Insured Damage ('000 US$)                    float64\n",
      "Insured Damage, Adjusted ('000 US$)          float64\n",
      "Total Damage ('000 US$)                      float64\n",
      "Total Damages ('000 US$)                     float64\n",
      "CPI                                          float64\n",
      "Admin Units                                   object\n",
      "Entry Date                                    object\n",
      "Last Update                                   object\n",
      "dtype: object\n",
      "df2 columns and types:\n",
      " Year                           object\n",
      "Seq                             int64\n",
      "Glide                          object\n",
      "Disaster Group                 object\n",
      "Disaster Subgroup              object\n",
      "Disaster Type                  object\n",
      "Disaster Subtype               object\n",
      "Disaster Subsubtype            object\n",
      "Event Name                     object\n",
      "Country                        object\n",
      "ISO                            object\n",
      "Region                         object\n",
      "Continent                      object\n",
      "Location                       object\n",
      "Origin                         object\n",
      "Associated Dis                 object\n",
      "Associated Dis2                object\n",
      "OFDA Response                  object\n",
      "Appeal                         object\n",
      "Declaration                    object\n",
      "Aid Contribution              float64\n",
      "Magnitude                     float64\n",
      "Magnitude Scale                object\n",
      "Latitude                      float64\n",
      "Longitude                     float64\n",
      "Local Time                     object\n",
      "River Basin                    object\n",
      "Start Year                      int64\n",
      "Start Month                   float64\n",
      "Start Day                     float64\n",
      "End Year                        int64\n",
      "End Month                     float64\n",
      "End Day                       float64\n",
      "Total Deaths                  float64\n",
      "No. Injured                   float64\n",
      "No. Affected                  float64\n",
      "No. Homeless                  float64\n",
      "Total Affected                float64\n",
      "Insured Damages ('000 US$)    float64\n",
      "Total Damages ('000 US$)      float64\n",
      "CPI                           float64\n",
      "Adm Level                      object\n",
      "Admin1 Code                    object\n",
      "Admin2 Code                    object\n",
      "Geo Locations                  object\n",
      "dtype: object\n",
      "Merged data successfully saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Print column names and types to debug\n",
    "print(\"df1 columns and types:\\n\", emdat_df.dtypes)\n",
    "print(\"df2 columns and types:\\n\", kaggle_df.dtypes)\n",
    "\n",
    "# Rename 'DisNo.' to 'Year' in df1 if it exists\n",
    "if 'DisNo.' in emdat_df.columns:\n",
    "    emdat_df.rename(columns={'DisNo.': 'Year'}, inplace=True)\n",
    "\n",
    "# Convert 'Year' to int if possible, or keep it as a string\n",
    "emdat_df['Year'] = emdat_df['Year'].astype(str).str[:4]  # Ensure it's a 4-digit string\n",
    "kaggle_df['Year'] = kaggle_df['Year'].astype(str)  # Convert to string for matching\n",
    "\n",
    "# Rename other columns\n",
    "emdat_df.rename(columns={\"Total Damages ('000 US$')\": \"Total Damages ('000 US$)\"}, inplace=True)\n",
    "kaggle_df.rename(columns={'Dis Mag Value': 'Magnitude', 'Dis Mag Scale': 'Magnitude Scale', \n",
    "                    'No Injured': 'No. Injured', 'No Affected': 'No. Affected', \n",
    "                    'No Homeless': 'No. Homeless'}, inplace=True)\n",
    "\n",
    "# Define merge columns\n",
    "merge_columns = [\n",
    "    \"Year\", \"Disaster Group\", \"Disaster Subgroup\", \"Disaster Type\", \"ISO\",\n",
    "    \"Latitude\", \"Longitude\", \"Start Year\", \"Start Month\", \"Start Day\", \n",
    "    \"End Year\", \"End Month\", \"End Day\", \"Total Deaths\", \"No. Injured\", \n",
    "    \"No. Affected\", \"No. Homeless\", \"Total Affected\", \"Total Damages ('000 US$)\", \n",
    "    \"CPI\", \"Magnitude\", \"Magnitude Scale\"\n",
    "]\n",
    "\n",
    "# Check for missing columns\n",
    "missing_cols_df1 = [col for col in merge_columns if col not in emdat_df.columns]\n",
    "missing_cols_df2 = [col for col in merge_columns if col not in kaggle_df.columns]\n",
    "\n",
    "if missing_cols_df1 or missing_cols_df2:\n",
    "    print(\"Missing columns in df1:\", missing_cols_df1)\n",
    "    print(\"Missing columns in df2:\", missing_cols_df2)\n",
    "else:\n",
    "    # Merge DataFrames\n",
    "    merged_df = pd.merge(emdat_df, kaggle_df, on=merge_columns, how=\"inner\")\n",
    "\n",
    "    # Drop duplicates and null values\n",
    "    merged_df = merged_df.dropna().drop_duplicates()\n",
    "\n",
    "    # Save the merged data\n",
    "    merged_df.to_csv('Datasets/integrated_data.csv', index=False)\n",
    "    print(\"Merged data successfully saved!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
